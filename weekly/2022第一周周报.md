# 1月8日日报

## 目标

打算先通过修改代码在已跑通的pytorch版本Deeplab里测试连续帧，然后再调试官方版本

## 步骤

连续帧不仅需要将视频分割成单张图片，连续帧怎么包含标注还是个难题

思路:视频->图像--(预测输出)--图像->视频

1、现有数据集的60张图片一起预测，打印结果

2、60张图片合成视频（manual），视频分割成图片（函数），一起预测，打印结果

3、一起预测的结果合成视频输出

4、找网上的连续帧数据集预测

## 成果

1. 在Pytorch简化版本上实现了对新数据的推理，时效在6张图片每秒

2. 学会在github上通过新建branches、提交PR等实现代码的远程仓库同步
## 问题点

#### RuntimeError: The size of tensor a (30) must match the size of tensor b (54) at non-singleton dimension 0

问题：RT，下一组数据集的又变成RuntimeError: The size of tensor a (30) must match the size of tensor b (36) at non-singleton dimension 0，后面tensor b的值在不断变化

解决：全景分割里面初始设定的mask的数量是30个，数据集里的mask多于了30个，这时需要把初始mask数量调大

后续问题：初始设定的mask过大，会导致显存占用过大，因为它会让所有数据集的mask数扩大为设定的数量

#### loss出现负数

由于加了mask数量，可能导致了loss计算方法有误，还未解决，觉得可能在官方库函数跑的时候能解决

### github

#### 拉取后不同步

将GithubDesktop中Current branch中多余的分支删除掉，然后基于master建立新的分支

#### 该代码每次训练的数据集都是同一batch的图片，初始的预测也是同一batch的图片，但是训练时候指针指向下一数据集过快，会导致loss来不及收敛

## 视频全景分割

两个子任务：单目深度估计（从单个图像预测深度）和视频全景分割（实例分割和语义分割）

## 明日任务

把ViP-deeplab数据集搞懂，再想怎么做出连续帧，然后对连续帧做标注，或者找到加载连续帧数据集的代码，可以的话跑一遍

